---
layout:     post
title:      吴恩达机器学习笔记
subtitle:   Normal Equation
date:       2019-01-13
author:     Raymond
header-img: img/home-bg-o.jpg
catalog: true
tags:
    - 机器学习

---



## Normal Equation(标准方程)

通过前面的学习，我们知道了能够通过梯度下降的方法求得我们的最优解，那还有没有其他方法呢？
回想我们原来的学习过程，如果我们已知一个二次函数，想求它的最小值，我们采用的方法就是对二次函数求导，找到导数为0的那个点，这就是Normal Equation的方法
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190115212942145.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80Mjk3MDQ1Ng==,size_16,color_FFFFFF,t_70)
如上图所示，我们得到一个关于变量的矩阵X，和一个输出的矩阵Y，利用
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190115213100179.png)
来求的我们的θ向量，关于这个式子怎么求得需要用到比较多的数学知识，只需理解记住即可。
## 与梯度函数比较
采用这种方法，我们不需要很多次的迭代，也不需要考虑如何选取我们的α，但是在求逆矩阵的那一步，需要的时间复杂度是O（$n^3$）,而采用梯度下降是O($kn^2$),当我们的特征值很多时（一般超过10,000个）一般来说采用梯度下降的方法速度会更快，而且梯度下降在以后的更高级的机器学习算法中也会有很多的应用。